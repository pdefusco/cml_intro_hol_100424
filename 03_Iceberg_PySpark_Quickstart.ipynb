{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "private-diversity",
   "metadata": {},
   "source": [
    "# Using Apache Iceberg with Spark 3 in CML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-silly",
   "metadata": {},
   "source": [
    "The official documentation for Apache Iceberg with Spark is located at [this link](https://iceberg.apache.org/#getting-started/#using-iceberg-in-spark-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-burns",
   "metadata": {},
   "source": [
    "For a full list of Apache Iceberg terms, please visit [this link](https://iceberg.apache.org/#terms/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8467cdd5-6445-4ef7-868e-9f6dad752d80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cml.data_v1 as cmldata\n",
    "\n",
    "# Sample in-code customization of spark configurations\n",
    "#from pyspark import SparkContext\n",
    "#SparkContext.setSystemProperty('spark.executor.cores', '1')\n",
    "#SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "\n",
    "CONNECTION_NAME = \"go01-aw-dl\"\n",
    "\n",
    "conn = cmldata.get_connection(CONNECTION_NAME)\n",
    "spark = conn.get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53febf51-4fb8-4879-92d9-808fb39edf06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "username = os.environ[\"PROJECT_OWNER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-immune",
   "metadata": {},
   "source": [
    "#### You can use simple Spark SQL commands to create Spark tables as you always have. Just make sure to specify the USING iceberg clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extended-stopping",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS default.{}_ice (id bigint, data string) USING iceberg\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-pickup",
   "metadata": {},
   "source": [
    "#### To select a specific table snapshot or the snapshot at some time, Iceberg supports two Spark read options:\n",
    "\n",
    "* snapshot-id selects a specific table snapshot\n",
    "* as-of-timestamp selects the current snapshot at a timestamp, in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-definition",
   "metadata": {},
   "source": [
    "#### You can view all snapshots associated with the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ec587b-605f-4a1c-9d42-292d02ed1b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, data: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM default.{}_ice\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-place",
   "metadata": {},
   "source": [
    "#### Or a full table version history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adequate-mediterranean",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2024-03-16 00:53:23.233|2952744008021118981|null               |true               |\n",
      "|2024-03-16 00:55:07.633|4221471412694680144|2952744008021118981|true               |\n",
      "|2024-03-16 00:55:26.894|2773036698405268957|4221471412694680144|true               |\n",
      "|2024-03-16 00:55:28.269|5208843994265553390|2773036698405268957|true               |\n",
      "|2024-03-16 00:55:29.615|3789197272971574187|5208843994265553390|true               |\n",
      "|2024-03-16 00:55:31.048|4009769249131678601|3789197272971574187|true               |\n",
      "|2024-03-16 00:55:32.441|428428724457144922 |4009769249131678601|true               |\n",
      "|2024-03-16 00:55:33.823|7443296050635542790|428428724457144922 |true               |\n",
      "|2024-03-16 00:55:35.212|7363979166116357902|7443296050635542790|true               |\n",
      "|2024-03-16 00:55:36.613|3223179238839827744|7363979166116357902|true               |\n",
      "|2024-03-16 00:55:38.066|2123958492348500891|3223179238839827744|true               |\n",
      "|2024-03-16 00:55:39.566|7439239574070700200|2123958492348500891|true               |\n",
      "|2024-03-16 00:55:40.927|2586918814928512135|7439239574070700200|true               |\n",
      "|2024-03-16 00:55:42.259|668354122848994746 |2586918814928512135|true               |\n",
      "|2024-03-16 00:55:43.593|5709140876788939064|668354122848994746 |true               |\n",
      "|2024-03-16 00:55:44.976|2347616516704750950|5709140876788939064|true               |\n",
      "|2024-03-16 00:55:46.408|4879605202613769402|2347616516704750950|true               |\n",
      "|2024-03-16 00:55:47.841|7465250053305413241|4879605202613769402|true               |\n",
      "|2024-03-16 00:55:49.228|158175975727299293 |7465250053305413241|true               |\n",
      "|2024-03-16 00:55:50.541|3497752302619877222|158175975727299293 |true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"default.{}_ice.history\".format(username)).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-brooklyn",
   "metadata": {},
   "source": [
    "##### A manifest file is a metadata file that lists a subset of data files that make up a snapshot.\n",
    "\n",
    "##### Each data file in a manifest is stored with a partition tuple, column-level stats, and summary information used to prune splits during scan planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-participant",
   "metadata": {},
   "source": [
    "##### To show a table’s file manifests and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solid-container",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "|content|path                                                                                                                                                                          |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries|\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "|0      |s3a://go01-demo/warehouse/tablespace/external/hive/akahan_replication/warehouse/tablespace/external/hive/pauldefusco_ice/metadata/2efbc058-a880-4e18-b579-307130868d62-m0.avro|5828  |0                |7645187750180863762|1                     |0                        |0                       |0                       |0                          |0                         |[]                 |\n",
      "|0      |s3a://go01-demo/warehouse/tablespace/external/hive/akahan_replication/warehouse/tablespace/external/hive/pauldefusco_ice/metadata/028013d4-7d3c-4167-8328-fe2860a2a30b-m0.avro|5829  |0                |8252338645258915976|1                     |0                        |0                       |0                       |0                          |0                         |[]                 |\n",
      "|0      |s3a://go01-demo/warehouse/tablespace/external/hive/akahan_replication/warehouse/tablespace/external/hive/pauldefusco_ice/metadata/f9adebfc-8fa2-433f-9e61-9828bb6d202b-m0.avro|5829  |0                |7430815557577608449|1                     |0                        |0                       |0                       |0                          |0                         |[]                 |\n",
      "|0      |s3a://go01-demo/warehouse/tablespace/external/hive/akahan_replication/warehouse/tablespace/external/hive/pauldefusco_ice/metadata/b1247a37-9789-46c6-afe5-9a047b4543e3-m0.avro|5826  |0                |7685499577091434846|1                     |0                        |0                       |0                       |0                          |0                         |[]                 |\n",
      "|0      |s3a://go01-demo/warehouse/tablespace/external/hive/akahan_replication/warehouse/tablespace/external/hive/pauldefusco_ice/metadata/165a8779-652d-489d-bcb4-d9e38d78bbfc-m0.avro|5827  |0                |8262632703873553986|1                     |0                        |0                       |0                       |0                          |0                         |[]                 |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"default.{}_ice.manifests\".format(username)).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-smith",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-laser",
   "metadata": {},
   "source": [
    "### Using snapshots as shown above, we can insert some data into the table and roll back to its original state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "present-venezuela",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO default.{}_ice VALUES (1, 'x'), (2, 'y'), (3, 'z')\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faced-praise",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  6|   w|\n",
      "| 10|   S|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  6|   N|\n",
      "|  8|   I|\n",
      "|  9|   Q|\n",
      "|  0|   x|\n",
      "|  8|   c|\n",
      "|  3|   G|\n",
      "|  3|   C|\n",
      "|  7|   u|\n",
      "|  9|   G|\n",
      "|  0|   E|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  5|   r|\n",
      "|  4|   r|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using select\n",
    "spark.sql(\"SELECT * FROM default.{}_ice\".format(username)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subtle-samuel",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp = 1712681548.088943\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "timestamp = datetime.timestamp(now)\n",
    "print(\"timestamp =\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "expanded-neighbor",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  6|   w|\n",
      "| 10|   S|\n",
      "|  6|   N|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  8|   I|\n",
      "|  9|   Q|\n",
      "|  3|   G|\n",
      "|  0|   x|\n",
      "|  8|   c|\n",
      "|  3|   C|\n",
      "|  9|   G|\n",
      "|  7|   u|\n",
      "|  4|   r|\n",
      "|  0|   E|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  5|   r|\n",
      "|  3|   p|\n",
      "|  6|   B|\n",
      "|  6|   T|\n",
      "|  6|   c|\n",
      "|  6|   V|\n",
      "|  5|   D|\n",
      "|  5|   j|\n",
      "|  7|   p|\n",
      "|  6|   E|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  9|   U|\n",
      "| 10|   v|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using a point in time\n",
    "df = spark.read.option(\"as-of-timestamp\", int(timestamp*1000)).format(\"iceberg\").load(\"default.{}_ice\".format(username))\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parallel-ethnic",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO default.{}_ice VALUES (1, 'd'), (2, 'e'), (3, 'f')\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67832e-4a4c-45f3-b49b-b05bdad33996",
   "metadata": {},
   "source": [
    "#### Let's insert more data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3293abf-bb3e-46bd-a993-0a0d10642238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert using Iceberg format\n",
    "import string\n",
    "import random\n",
    "\n",
    "for i in range(25):\n",
    "    number = random.randint(0, 10)\n",
    "    letter = random.choice(string.ascii_letters)\n",
    "    spark.sql(\"INSERT INTO default.{}_ice VALUES ({}, '{}')\".format(username, number, letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e10c40-d142-4858-85af-4d61996eb3cf",
   "metadata": {},
   "source": [
    "#### Now let's access the data again. Let's access it with the same timestemp as before. Notice we have a smaller number of rows than we just inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd0858e-93cf-4bbc-97d1-1055cb72bb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  6|   w|\n",
      "| 10|   S|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  6|   N|\n",
      "|  8|   I|\n",
      "|  0|   x|\n",
      "|  9|   Q|\n",
      "|  3|   G|\n",
      "|  8|   c|\n",
      "|  3|   C|\n",
      "|  7|   u|\n",
      "|  9|   G|\n",
      "|  0|   E|\n",
      "|  4|   r|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  5|   r|\n",
      "|  3|   p|\n",
      "|  6|   B|\n",
      "|  6|   T|\n",
      "|  6|   c|\n",
      "|  5|   D|\n",
      "|  6|   V|\n",
      "|  5|   j|\n",
      "|  7|   p|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  6|   E|\n",
      "|  9|   U|\n",
      "| 10|   v|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using a point in time\n",
    "df = spark.read.option(\"as-of-timestamp\", int(timestamp*1000)).format(\"iceberg\").load(\"default.{}_ice\".format(username))\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbabc8-ef2e-4fdf-84cd-3cbf40b3391c",
   "metadata": {},
   "source": [
    "### Observe that many new Snapshots have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35f7a32-7e20-41cd-9793-a963100eeac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2024-03-16 00:53:23.233|2952744008021118981|null               |true               |\n",
      "|2024-03-16 00:55:07.633|4221471412694680144|2952744008021118981|true               |\n",
      "|2024-03-16 00:55:26.894|2773036698405268957|4221471412694680144|true               |\n",
      "|2024-03-16 00:55:28.269|5208843994265553390|2773036698405268957|true               |\n",
      "|2024-03-16 00:55:29.615|3789197272971574187|5208843994265553390|true               |\n",
      "|2024-03-16 00:55:31.048|4009769249131678601|3789197272971574187|true               |\n",
      "|2024-03-16 00:55:32.441|428428724457144922 |4009769249131678601|true               |\n",
      "|2024-03-16 00:55:33.823|7443296050635542790|428428724457144922 |true               |\n",
      "|2024-03-16 00:55:35.212|7363979166116357902|7443296050635542790|true               |\n",
      "|2024-03-16 00:55:36.613|3223179238839827744|7363979166116357902|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"default.{}_ice.history\".format(username)).show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97793e-b86b-4c42-8b85-68397bc44d18",
   "metadata": {},
   "source": [
    "### You can also query the table in its previous state as of a specific partition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938fd327-6b8a-4bae-8449-1383daaf1bdc",
   "metadata": {},
   "source": [
    "#### Copy paste a snapshot_id from above and paste it in the next Spark command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e5621db-65e2-47c4-a3a9-e3422b780c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  6|   B|\n",
      "|  5|   r|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  9|   G|\n",
      "|  6|   E|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  9|   Q|\n",
      "|  3|   z|\n",
      "|  9|   U|\n",
      "|  5|   D|\n",
      "| 10|   v|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read\\\n",
    "    .option(\"snapshot-id\", 3223179238839827744)\\\n",
    "    .table(\"default.{}_ice\".format(username)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d0f6b-59a5-41f2-ba9b-2e1e8aa0d352",
   "metadata": {},
   "source": [
    "### The Iceberg API allows you to create tables from Spark Dataframes, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0efe36e2-b1cb-47ef-bed4-f902c1e232d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df = spark.sql(\"SELECT * FROM default.{}_ice\".format(username)).sample(fraction=0.5, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fbcfc09-8874-4dfb-87ad-7bc64d6d7471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'), ('data', 'string')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a3b301e-dfa7-445e-af5a-0d421ad32a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  6|   w|\n",
      "|  8|   I|\n",
      "|  3|   G|\n",
      "|  6|   B|\n",
      "|  6|   E|\n",
      "|  3|   f|\n",
      "|  7|   R|\n",
      "|  7|   T|\n",
      "|  2|   e|\n",
      "|  9|   Q|\n",
      "+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73ee2b-2da0-4551-afe3-6af5b70aca15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
